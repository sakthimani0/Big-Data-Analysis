from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Netflix Dataset Analysis") \
    .getOrCreate()
df.groupBy("type").count().show()
df.groupBy("country").count().orderBy("count", ascending=False).show(10)
df.groupBy("type").count().show()
from pyspark.sql.functions import explode, split

genre_df = df.select(explode(split("listed_in", ", ")).alias("genre"))
genre_df.groupBy("genre").count().orderBy("count", ascending=False).show(10)
df.groupBy("director").count().orderBy("count", ascending=False).show(10)
df.groupBy("release_year").count().orderBy("release_year").show()
from pyspark.sql.functions import regexp_extract, col

duration_df = df.withColumn("duration_num", regexp_extract("duration", r"(\d+)", 1).cast("int"))
duration_df.groupBy("type").avg("duration_num").show()
df.filter((df.title.contains("Love")) & (df.release_year > 2015)).select("title", "release_year").show(10)
df2 = df.select("show_id", "title").withColumnRenamed("title", "title_2")
joined_df = df.join(df2, on="show_id", how="inner")
joined_df.select("show_id", "title", "title_2").show()
from pyspark.sql.functions import explode, split

cast_df = df.select(explode(split("cast", ", ")).alias("actor")).filter("actor IS NOT NULL")
cast_df.groupBy("actor").count().orderBy("count", ascending=False).show(10)
